---
title: "NLP Series - NLP Pipeline"
excerpt: "Natural Language Processing using Pyspark"
date:   2021-04-15 22:12:28 -0500
theme : "mint"
---

<img src="/img/Learning/NLP/nlp-pipeline.png" alt="this is a placeholder image" width="100%" height = "50%" class="center" >

> <span style="font-family:Georgia; font-size:20px;"> Natural Language Processing Basics - NLP Pipeline</span>   

<span style="font-family:Georgia; font-size:16px;"> If there's one form of media which we are exposed to every single day, it's text. There is huge amounts of data created by people and devices, every single day. This data includes and is not limited to comments on social media, product reviews, tweets and reddit messages. Generally speaking, the data from these sources are useful for the purposes of research and commerce. </span>  

<span style="font-family:Georgia; font-size:16px;"> A NLP pipeline, refers to the series of steps involved in a text-processing pipeline used for any NLP application development. In this article, we will learn about the various steps involved and how they play important roles in solving the NLP problem. </span>  

<span style="font-family:Georgia; font-size:16px;"> The key stages of a NLP pipeline for a data-driven NLP system are as follows.</span>

<span style="font-family:Georgia; font-size:16px;"> 1. [Data acquisition](#data-acquisition)</span>   
<span style="font-family:Georgia; font-size:16px;"> 2. [Text cleaning](#text-cleaning)</span>   
<span style="font-family:Georgia; font-size:16px;"> 3. [Pre-processing](#pre-processing)</span>   
<span style="font-family:Georgia; font-size:16px;"> 4. [Feature engineering](#feature-engineering)<span>   
<span style="font-family:Georgia; font-size:16px;"> 5. [Modeling](#modeling)</span>   
<span style="font-family:Georgia; font-size:16px;"> 6. [Evaluation](#evaluation)</span>   
<span style="font-family:Georgia; font-size:16px;"> 7. [Deployment](#deployment)</span>   
<span style="font-family:Georgia; font-size:16px;"> 8. [Monitoring & Updating Model](#monitoring--updating-model)</span>   


<span style="font-family:Georgia; font-size:16px;"> Before we dive into the details of each stage of the NLP pipeline, its important to note that each of these steps may depend on the specific NLP task at hand. A text classification task may require different stages compared to a text summarization tasl.</span>

### Data Acquisition

<span style="font-family:Georgia; font-size:16px;"> Data is the heart of the machine learning world and therefore its vital to undetstand the source of data and the strategies useful for gathering data. There are several ways to collect data. Firstly, we could check if there are any publicly available datasets for the task at hand. These refer to the pre-cleaned, freely available datasets. When our problem statement aligns with a clean, pre-existing, properly formulated dataset, we should certainly take advantage of existing, open-source expertise.</span>   

<span style="font-family:Georgia; font-size:16px;">Although there are a number of publicly available datasets for a wide range of NLP tasks, its not always guaranteed that these can be used for every task. They are mostly beneficial for generic NLP tasks and not much useful as the task gets more specific.  In that case, the next strategy would be to scrape data on the internet. Web Scraping is one of the versatile strategies that allows us to extract data from websites. Once extracted, this information is cleaned and converted into a structured form for further analysis. For many industrial settings, this is not sufficient either. In cases when the problem statement is too specific to generalize over an open-source dataset, we start looking for data within the organization. In other words, we use private data generated by the machine learning engineers. While instrumenting data is quite beneficial, it takes time. Data Augmentation is one of the techniques used to remedy the issue of latency in this scenario. </span>   

<span style="font-family:Georgia; font-size:16px;">The purpose of data augmentation is to exploit language properties in order to create text that is syntactically similar to source text. Some of the common tricks used to achieve data augmentation include synonym replacement , back translation, TF-IDFâ€“based word replacement, bigram flipping, replacing entities and adding noise to data. More advanced techniques for data augmentation include Snorkel, Easy Data Augmentation (EDA) and active learning.  </span>   


### Text Cleaning

### Pre-Processing

### Feature Engineering

### Modeling

### Evaluation

### Deployment

### Monitoring & Updating Model


### Glossary

<span style="font-family:Georgia; font-size:16px;">Synonym Replacement</span>   

<span style="font-family:Georgia; font-size:16px;">Back Translation</span>   

<span style="font-family:Georgia; font-size:16px;">Bigram Flipping</span>   

<span style="font-family:Georgia; font-size:16px;">Replacing entities</span>   

<span style="font-family:Georgia; font-size:16px;">Adding noise to data</span>   

<span style="font-family:Georgia; font-size:16px;">Snorkel</span>   

<span style="font-family:Georgia; font-size:16px;">Easy Data Augmentation (EDA)    </span>   

<span style="font-family:Georgia; font-size:16px;">Active learning</span>   


<span style="font-family:Georgia; font-size:16px;"> Thanks for reading! I hope you found this article helpful. Read more data science articles <a href="https://prabhupavitra.github.io/learning/"> here </a> including tutorials from beginner to advanced levels!  </span> 
